{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517604ba",
   "metadata": {},
   "source": [
    "# 색상 인지시키기\n",
    "- 모델링 : CNN, colab\n",
    "- 모델링 방법\n",
    "    - 목적 : 특정 사진이 들어 갔을 때, 사람 얼굴을 인지하고, 그 부분의 색중 대부분의 색을 뽑아내어, 매치시키기\n",
    "        - Mean-shift clustering이라는 이미지 세그먼테이션 기법 ( 대표색 뽑아내기 )( 이게 구현이 쉬워 ) ( 정 안될 때, 최후의 보루)\n",
    "        - Foreground Extraction 기법 사용( 주요 오프젝트 추출하기 )\n",
    "          ( GrabCut 알고리즘( 대상 물체 라인따는 알고리즘 )을 활용하여 Foreground Extraction을 수행 )\n",
    "        - 위의 두가지 알고리즘을 대표하는 딥러닝 기법 ( GRAD-CAM )\n",
    "        - Grad-CAM heatmap 정보와 guided backpropagation 정보를 혼합해서 GrabCut 알고리즘의 초기 mask로 사용하면 위에서 나열했던 여러 가지 문제점을 해결할 수 있음. 최종적으로 추출해낸 foreground 영역과 색상 정보\n",
    "        \n",
    "    - 사람 피부색에 해당하는 컬러셋 확보\n",
    "        - 선행되야할 고민\n",
    "        \n",
    "            - 무슨 모델로 학습시킬 것인가?\n",
    "            - 연속적인 데이터 처리는 어떻게 해야할까?\n",
    "        \n",
    "    - 이미지 인지는, CNN 을 통해 하고 GRID-CAM을 적용하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66a8d0",
   "metadata": {},
   "source": [
    "#### https://github.com/sjchoi86/deep-uncertainty/blob/master/code/demo_gradcam_resnet50.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72413e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "• 위의 이미지에서 시각화에 준 condition(Cat / Dog)에 따라 그에\n",
    "대응되는 부분만 표시해주는 것을 볼 수 있음\n",
    "• 이미지에서 heatmap을 계산하는 것이므로 앞에서 나온 Guided\n",
    "Backpropagation과 결합해 Guided-Grad-CAM으로도 사용 가능\n",
    "\n",
    "    class GradCAM:\n",
    "\n",
    "  def __init__(self, module, target_layer):\n",
    "    self.module = module\n",
    "    self.target_layer = target_layer\n",
    "    self.target_output = None\n",
    "    self.target_output_grad = None\n",
    "\n",
    "    def forward_hook(_, __, output):\n",
    "      self.target_output = output.clone()\n",
    "    \n",
    "    def backward_hook(_, __, grad_output):\n",
    "      assert len(grad_output) == 1\n",
    "      self.target_output_grad = grad_output[0].clone()\n",
    "\n",
    "    self.target_layer.register_forward_hook(forward_hook)\n",
    "    self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def forward_pass(self, image):\n",
    "      self.module.eval()\n",
    "      self.module.zero_grad()\n",
    "      return self.module(image)\n",
    "\n",
    "    def get_grad_cam(self, image, target_class = None):\n",
    "      assert len(image.size()) == 3\n",
    "      image = image.unsqueeze(0)\n",
    "      out = self.forward_pass(image)\n",
    "      if target_class is None:\n",
    "        target_class = torch.argmax(out).item()\n",
    "        print('Target class is {}({})'.format(target_class, utils.index_to_class(target_class)))\n",
    "\n",
    "      onehot = utils.onehot(target_class, out_size(1))\n",
    "      onehot = onehot.unsqueeze(0)\n",
    "      out.backward(onehot)\n",
    "\n",
    "      grad = self.target_output_grad\n",
    "      grad = F.adaptive_avg_pool2d(grad, 1)\n",
    "\n",
    "      feature = self.target_output\n",
    "      feature = feature*grad\n",
    "      feature = torch.sum(feature, dim =1)\n",
    "      feature = F.relu(feature)\n",
    "\n",
    "      return feature.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ffef74",
   "metadata": {},
   "source": [
    "#### skin_Detection 방법 1\n",
    "\n",
    "- opencv 방법\n",
    "    - 목적이 skin_Detection 을 한 후에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ab395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Open a simple image\n",
    "img=cv2.imread(\"6_A_hgr2B_id05_1.jpg\")\n",
    "\n",
    "#converting from gbr to hsv color space\n",
    "img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#skin color range for hsv color space \n",
    "HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "#converting from gbr to YCbCr color space\n",
    "img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "#skin color range for hsv color space \n",
    "YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "#merge skin detection (YCbCr and hsv)\n",
    "global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "global_mask=cv2.medianBlur(global_mask,3)\n",
    "global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))\n",
    "\n",
    "\n",
    "HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "global_result=cv2.bitwise_not(global_mask)\n",
    "\n",
    "\n",
    "#show results\n",
    "# cv2.imshow(\"1_HSV.jpg\",HSV_result)\n",
    "# cv2.imshow(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "# cv2.imshow(\"3_global_result.jpg\",global_result)\n",
    "# cv2.imshow(\"Image.jpg\",img)\n",
    "cv2.imwrite(\"1_HSV.jpg\",HSV_result)\n",
    "cv2.imwrite(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "cv2.imwrite(\"3_global_result.jpg\",global_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663a12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d91c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4499f4b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
