{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f9626da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomUnderSampler' object has no attribute 'fit_sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f341b8cdc6c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n\u001b[0;32m     27\u001b[0m                                                     random_state=10)\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mX_samp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_samp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomUnderSampler' object has no attribute 'fit_sample'"
     ]
    }
   ],
   "source": [
    "# 평가 지표 평균 90 이상\n",
    "import pandas as pd\n",
    "from numpy import mean, std\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import *\n",
    "\n",
    "df = pd.read_csv('./TravelInsurancePrediction.csv')\n",
    "df['FrequentFlyer'] = df['FrequentFlyer'].map({'Yes': 1, 'No': 0})\n",
    "df['EverTravelledAbroad'] = df['EverTravelledAbroad'].map({'Yes': 1, 'No': 0})\n",
    "df[\"Employment Type\"] = df[\"Employment Type\"].map({\"Government Sector\" : 1, \"Private Sector/Self Employed\" : 0})\n",
    "\n",
    "df = df.drop([\"GraduateOrNot\"] , axis=1)\n",
    "\n",
    "ndf = df[['Age', 'AnnualIncome', 'ChronicDiseases', \n",
    "          'FrequentFlyer', 'FamilyMembers', 'Employment Type',\n",
    "          'EverTravelledAbroad', 'TravelInsurance']]\n",
    "X = ndf[list(ndf.columns)[:-1]]\n",
    "y = ndf[list(ndf.columns)[-1]]\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=10)\n",
    "X_samp, y_samp = RandomUnderSampler(random_state=0).fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9441de9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e0422e27ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mrv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sp' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import *\n",
    "\n",
    "n0 = 200; n1 = 20\n",
    "rv1 = sp.stats.multivariate_normal([-1, 0], [[1, 0], [0, 1]])\n",
    "rv2 = sp.stats.multivariate_normal([+1, 0], [[1, 0], [0, 1]])\n",
    "X0 = rv1.rvs(n0, random_state=0)\n",
    "X1 = rv2.rvs(n1, random_state=0)\n",
    "X_imb = np.vstack([X0, X1])\n",
    "y_imb = np.hstack([np.zeros(n0), np.ones(n1)])\n",
    "\n",
    "x1min = -4; x1max = 4\n",
    "x2min = -2; x2max = 2\n",
    "xx1 = np.linspace(x1min, x1max, 1000)\n",
    "xx2 = np.linspace(x2min, x2max, 1000)\n",
    "X1, X2 = np.meshgrid(xx1, xx2)\n",
    "\n",
    "def classification_result2(X, y, title=\"\"):\n",
    "    plt.contour(X1, X2, rv1.pdf(np.dstack([X1, X2])), levels=[0.05], linestyles=\"dashed\")\n",
    "    plt.contour(X1, X2, rv2.pdf(np.dstack([X1, X2])), levels=[0.05], linestyles=\"dashed\")\n",
    "    model = SVC(kernel=\"linear\", C=1e4, random_state=0).fit(X, y)\n",
    "    Y = np.reshape(model.predict(np.array([X1.ravel(), X2.ravel()]).T), X1.shape)\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], marker='x', label=\"0 클래스\")\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], marker='o', label=\"1 클래스\")\n",
    "    plt.contour(X1, X2, Y, colors='k', levels=[0.5])\n",
    "    y_pred = model.predict(X)\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-3, 3)\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.title(title)\n",
    "    return model\n",
    "X_samp, y_samp = RandomUnderSampler(random_state=0).fit_sample(X_imb, y_imb)\n",
    "\n",
    "plt.subplot(121)\n",
    "classification_result2(X_imb, y_imb)\n",
    "plt.subplot(122)\n",
    "model_samp = classification_result2(X_samp, y_samp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bd8a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\moh12\\anaconda3\\envs\\multi\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\moh12\\anaconda3\\envs\\multi\\lib\\site-packages (from imbalanced-learn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\moh12\\anaconda3\\envs\\multi\\lib\\site-packages (from imbalanced-learn) (1.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\moh12\\anaconda3\\envs\\multi\\lib\\site-packages (from imbalanced-learn) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\moh12\\anaconda3\\envs\\multi\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.2.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "model2=RandomForestClassifier(criterion='entropy')\n",
    "\n",
    "X = ndf[list(ndf.columns)[:-1]]\n",
    "y = ndf[list(ndf.columns)[-1]]\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=10)\n",
    "t1 = TomekLinks()\n",
    "X_bal, y_bal = TomekLinks().fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adc542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9feb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b2c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce10410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf2 = df2[['Age', 'AnnualIncome', 'ChronicDiseases', \n",
    "          'FrequentFlyer', 'FamilyMembers', 'Employment Type',\n",
    "          'EverTravelledAbroad', 'TravelInsurance']]\n",
    "\n",
    "X = ndf2[list(ndf.columns)[:-1]]\n",
    "y = ndf2[list(ndf.columns)[-1]]\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균 92 프로\n",
    "ndf1 = df1[['Age', 'AnnualIncome', 'ChronicDiseases', \n",
    "          'FrequentFlyer', 'FamilyMembers', 'Employment Type',\n",
    "          'EverTravelledAbroad', 'TravelInsurance']]\n",
    "from sklearn import preprocessing\n",
    "X = ndf1[list(ndf.columns)[:-1]]\n",
    "y = ndf1[list(ndf.columns)[-1]]\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d90f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=10)\n",
    "from sklearn import tree\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# train data를 가지고 모형 학습m\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_hat = tree_model.predict(X_test)\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec243f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
