{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f9626da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1589, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>GraduateOrNot</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "      <th>TravelInsurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>27</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>34</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>29</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>35</td>\n",
       "      <td>1100000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>28</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  AnnualIncome  ChronicDiseases  GraduateOrNot  FrequentFlyer  \\\n",
       "1857   27        900000                0              1              0   \n",
       "685    34       1500000                1              1              1   \n",
       "1970   29        500000                0              1              0   \n",
       "1885   35       1100000                0              1              0   \n",
       "895    28        600000                0              1              0   \n",
       "\n",
       "      FamilyMembers  Employment Type  EverTravelledAbroad  TravelInsurance  \n",
       "1857              4                1                    0                0  \n",
       "685               4                0                    1                1  \n",
       "1970              4                0                    0                1  \n",
       "1885              3                1                    0                0  \n",
       "895               5                0                    1                1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가 지표 평균 90 이상\n",
    "import pandas as pd\n",
    "from numpy import mean, std\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import *\n",
    "\n",
    "df = pd.read_csv('./TravelInsurancePrediction.csv')\n",
    "df['FrequentFlyer'] = df['FrequentFlyer'].map({'Yes': 1, 'No': 0})\n",
    "df['EverTravelledAbroad'] = df['EverTravelledAbroad'].map({'Yes': 1, 'No': 0})\n",
    "df[\"Employment Type\"] = df[\"Employment Type\"].map({\"Government Sector\" : 1, \"Private Sector/Self Employed\" : 0})\n",
    "df['GraduateOrNot'] = df['GraduateOrNot'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# df = df.drop([\"GraduateOrNot\"] , axis=1)\n",
    "df_index = ['Age', 'AnnualIncome', 'ChronicDiseases',\"GraduateOrNot\", \n",
    "          'FrequentFlyer', 'FamilyMembers', 'Employment Type',\n",
    "          'EverTravelledAbroad']\n",
    "df_label_index = ['TravelInsurance']\n",
    "ndf = df[['Age', 'AnnualIncome', 'ChronicDiseases', 'GraduateOrNot',\n",
    "          'FrequentFlyer', 'FamilyMembers', 'Employment Type',\n",
    "          'EverTravelledAbroad', 'TravelInsurance']]\n",
    "X = ndf[list(ndf.columns)[:-1]]\n",
    "y = ndf[list(ndf.columns)[-1]]\n",
    "# y = y.astype({'TravelInsurance': int})\n",
    "# X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=10)\n",
    "print(X_train.shape)\n",
    "df_new = pd.concat([X_train,y_train], axis = 1)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incom>132500 이상, 가족이 5.5 명 이상 이걸 오버샘플링해보자\n",
    "ndf1 = df[['Age', 'AnnualIncome', 'Employment Type',\n",
    "           'TravelInsurance']]\n",
    "X1 = ndf[list(ndf.columns)[:-1]]\n",
    "y1 = ndf[list(ndf.columns)[-1]]\n",
    "# y = y.astype({'TravelInsurance': int})\n",
    "# X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, \n",
    "                                                    random_state=10)\n",
    "df_new = pd.concat([X_train,y_train], axis = 1)\n",
    "\n",
    "df_new = df_new[(df_new['AnnualIncome'] >= 1275000) | (df_new['FamilyMembers'] >= 5.5) | (df_new['Age'] >= 32.5)| (df_new['GraduateOrNot'] >= 0.5) ]\n",
    "X_train = df_new[list(ndf.columns)[:-1]]\n",
    "\n",
    "y_train = df_new[list(ndf.columns)[-1]]\n",
    "df_new.info()\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62692bb0",
   "metadata": {},
   "source": [
    "#### 언더샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9441de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 73, 재현율 70( 1) 그러나 (0 )이 70 대로 떨어짐\n",
    "enn = EditedNearestNeighbours()\n",
    "X_resampled, y_resampled  = enn.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현율 57 \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "nm1 = NearMiss(version=1)\n",
    "X_resampled, y_resampled = nm1.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "renn = RepeatedEditedNearestNeighbours()\n",
    "X_resampled, y_resampled = renn.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ab78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "allknn = AllKNN()\n",
    "X_resampled, y_resampled = allknn.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#언더 샘플링 중에는 제일 좋네 그나마\n",
    "cnn = CondensedNearestNeighbour(random_state=0)\n",
    "X_resampled, y_resampled = cnn.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 니가 일등이네\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "X_resampled, y_resampled = oss.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncr = NeighbourhoodCleaningRule()\n",
    "X_resampled, y_resampled = ncr.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4309eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "iht = InstanceHardnessThreshold(random_state=0,                                 estimator=LogisticRegression(\n",
    "                                    solver='lbfgs', multi_class='auto'))\n",
    "X_resampled, y_resampled = iht.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c15a81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caae6267",
   "metadata": {},
   "source": [
    "#### 오버샘플링 smotenc / smoten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b08c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 13)\n"
     ]
    }
   ],
   "source": [
    "# 가장 높은 점수 결정 나무, depth 5\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=[0, 2], random_state=0)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d870eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTEN\n",
    "sampler = SMOTEN(random_state=0)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4734883",
   "metadata": {},
   "source": [
    "#### 오버와 언더 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import *\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b3320",
   "metadata": {},
   "source": [
    "#### 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85bd8a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250   7]\n",
      " [ 58  83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       257\n",
      "           1       0.92      0.59      0.72       141\n",
      "\n",
      "    accuracy                           0.84       398\n",
      "   macro avg       0.87      0.78      0.80       398\n",
      "weighted avg       0.85      0.84      0.83       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "tree_model.fit(X_resampled, y_resampled)\n",
    "y_hat = tree_model.predict(X_test)\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    "bbc.fit(X_resampled, y_resampled) \n",
    "y_hat = bbc.predict(X_test)\n",
    "bbc_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(bbc_matrix)\n",
    "bbc_report = metrics.classification_report(y_test, y_hat)\n",
    "print(bbc_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9feb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=0)\n",
    "brf.fit(X_resampled, y_resampled) \n",
    "y_hat = brf.predict(X_test)\n",
    "brf_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(brf_matrix)\n",
    "brf_report = metrics.classification_report(y_test, y_hat)\n",
    "print(brf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec = EasyEnsembleClassifier(random_state=0)\n",
    "eec.fit(X_resampled, y_resampled)\n",
    "y_hat = eec.predict(X_test)\n",
    "eec_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(eec_matrix)\n",
    "eec_report = metrics.classification_report(y_test, y_hat)\n",
    "print(eec_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce1eeb",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce10410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤 포레스트는 오버샘플링이 좋음\n",
    "# 오버 언더 조합도 낫베드( 데이터 개수가 늘어날 수록 좋음)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_resampled , y_resampled)\n",
    "# rf_clf.fit(X_train , y_train)\n",
    "y_hat = rf_clf.predict(X_test)\n",
    "rf_clf_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(rf_clf_matrix)\n",
    "rf_clf_report = metrics.classification_report(y_test, y_hat)\n",
    "print(rf_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658f3ac",
   "metadata": {},
   "source": [
    "#### 결정트리 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda083de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tree_model, out_file=\"tree.dot\", \n",
    "                class_names=df_index , \n",
    "                feature_names = df_index, \n",
    "                impurity=True, \n",
    "                filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "# 위에서 생성된 tree.dot 파일을 Graphviz 읽어서 Jupyter Notebook상에서 시각화 \n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60ed96",
   "metadata": {},
   "source": [
    "#### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_resampled, y_resampled, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
    "                 eval_set=evals, verbose=True)\n",
    "y_hat = lgbm_wrapper.predict(X_test)\n",
    "lgbm_wrapper_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(lgbm_wrapper_matrix)\n",
    "lgbm_wrapper_report = metrics.classification_report(y_test, y_hat)\n",
    "print(lgbm_wrapper_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48add852",
   "metadata": {},
   "source": [
    "#### recall / precision\n",
    "\n",
    "- recall 은 대상물체를 빠뜨리지 않고 얼마나 잘 잡아내느냐\n",
    "- precision은 검출된 결과가 얼마나 정확한가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6cef3f",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba83f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train , label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test , label=y_test)\n",
    "params = { 'max_depth':3,\n",
    "           'eta': 0.1,\n",
    "           'objective':'binary:logistic',\n",
    "           'eval_metric':'logloss',\n",
    "           'early_stoppings':100\n",
    "        }\n",
    "num_rounds = 400\n",
    "# train 데이터 셋은 ‘train’ , evaluation(test) 데이터 셋은 ‘eval’ 로 명기합니다. \n",
    "wlist = [(dtrain,'train'),(dtest,'eval') ]\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달\n",
    "xgb_model = xgb.train(params = params , dtrain=dtrain , num_boost_round=num_rounds , evals=wlist )\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "\n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "\n",
    "get_clf_eval(y_test , preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b82fa9",
   "metadata": {},
   "source": [
    "#### Catboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(iterations=15)\n",
    "\n",
    "cat.fit(X_train, y_train)\n",
    "y_hat = cat.predict(X_test)\n",
    "cat_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(cat_matrix)\n",
    "cat_report = metrics.classification_report(y_test, y_hat)\n",
    "print(cat_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d90f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "a = ['ChronicDiseases',\"GraduateOrNot\",  'FrequentFlyer','Employment Type', 'EverTravelledAbroad' ]\n",
    "for i in range(len(a)):\n",
    "    print(list(combinations(a,i)), end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4bbbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean, std\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import *\n",
    "df = pd.read_csv('./TravelInsurancePrediction.csv')\n",
    "df['ChronicDiseases'] = df['ChronicDiseases'].map({1: \"Yes\", 0: 'No'})\n",
    "df['FrequentFlyer'] = df['FrequentFlyer'].map({'Yes': 1, 'No': 0})\n",
    "df['EverTravelledAbroad'] = df['EverTravelledAbroad'].map({'Yes': 1, 'No': 0})\n",
    "df[\"Employment Type\"] = df[\"Employment Type\"].map({\"Government Sector\" : 1, \"Private Sector/Self Employed\" : 0})\n",
    "df['GraduateOrNot'] = df['GraduateOrNot'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "ndf = pd.get_dummies(df[['Age', 'AnnualIncome', 'GraduateOrNot','ChronicDiseases',\n",
    "          'FrequentFlyer', 'FamilyMembers', 'Employment Type',\n",
    "          'EverTravelledAbroad']])\n",
    "\n",
    "ndf['FrequentFlyer'] = df['FrequentFlyer']\n",
    "ndf['TravelInsurance'] = df['TravelInsurance']\n",
    "X = ndf[list(ndf.columns)[:-1]]\n",
    "y = ndf[list(ndf.columns)[-1]]\n",
    "# y = y.astype({'TravelInsurance': int})\n",
    "# X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "da417714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./TravelInsurancePrediction.csv')\n",
    "df['ChronicDiseases'] = df['ChronicDiseases'].map({1: \"Yes\", 0: 'No'})\n",
    "df['FrequentFlyer'] = df['FrequentFlyer'].map({'Yes': 1, 'No': 0})\n",
    "# df['EverTravelledAbroad'] = df['EverTravelledAbroad'].map({'Yes': 1, 'No': 0})\n",
    "# df[\"Employment Type\"] = df[\"Employment Type\"].map({\"Government Sector\" : 1, \"Private Sector/Self Employed\" : 0})\n",
    "# df['GraduateOrNot'] = df['GraduateOrNot'].map({'Yes': 1, 'No': 0})\n",
    "# \n",
    "ndf = pd.get_dummies(df[['ChronicDiseases', 'GraduateOrNot','Employment Type','EverTravelledAbroad']])\n",
    "\n",
    "ndf1 = df[['Age', 'AnnualIncome', 'FrequentFlyer',\n",
    "           'FamilyMembers',\n",
    "           'TravelInsurance']]\n",
    "ndf = pd.concat([ndf, ndf1], axis = 1)\n",
    "# # ndf['TravelInsurance'] = df['TravelInsurance']\n",
    "X = ndf[list(ndf.columns)[:-1]]\n",
    "y = ndf[list(ndf.columns)[-1]]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "41ec243f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChronicDiseases_No</th>\n",
       "      <th>ChronicDiseases_Yes</th>\n",
       "      <th>GraduateOrNot_No</th>\n",
       "      <th>GraduateOrNot_Yes</th>\n",
       "      <th>Employment Type_Government Sector</th>\n",
       "      <th>Employment Type_Private Sector/Self Employed</th>\n",
       "      <th>EverTravelledAbroad_No</th>\n",
       "      <th>EverTravelledAbroad_Yes</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>FamilyMembers</th>\n",
       "      <th>TravelInsurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1250000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ChronicDiseases_No  ChronicDiseases_Yes  GraduateOrNot_No  \\\n",
       "0                   0                    1                 0   \n",
       "1                   1                    0                 0   \n",
       "2                   0                    1                 0   \n",
       "3                   0                    1                 0   \n",
       "4                   0                    1                 0   \n",
       "\n",
       "   GraduateOrNot_Yes  Employment Type_Government Sector  \\\n",
       "0                  1                                  1   \n",
       "1                  1                                  0   \n",
       "2                  1                                  0   \n",
       "3                  1                                  0   \n",
       "4                  1                                  0   \n",
       "\n",
       "   Employment Type_Private Sector/Self Employed  EverTravelledAbroad_No  \\\n",
       "0                                             0                       1   \n",
       "1                                             1                       1   \n",
       "2                                             1                       1   \n",
       "3                                             1                       1   \n",
       "4                                             1                       1   \n",
       "\n",
       "   EverTravelledAbroad_Yes  Age  AnnualIncome  FrequentFlyer  FamilyMembers  \\\n",
       "0                        0   31        400000              0              6   \n",
       "1                        0   31       1250000              0              7   \n",
       "2                        0   34        500000              0              4   \n",
       "3                        0   28        700000              0              3   \n",
       "4                        0   28        700000              1              8   \n",
       "\n",
       "   TravelInsurance  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0e5ac4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChronicDiseases</th>\n",
       "      <th>GraduateOrNot</th>\n",
       "      <th>EverTravelledAbroad</th>\n",
       "      <th>Employment Type_Government Sector</th>\n",
       "      <th>Employment Type_Private Sector/Self Employed</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>FrequentFlyer</th>\n",
       "      <th>FamilyMembers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1100000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ChronicDiseases  GraduateOrNot  EverTravelledAbroad  \\\n",
       "1857                0              1                    0   \n",
       "685                 1              1                    1   \n",
       "1970                0              1                    0   \n",
       "1885                0              1                    0   \n",
       "895                 0              1                    1   \n",
       "\n",
       "      Employment Type_Government Sector  \\\n",
       "1857                                  1   \n",
       "685                                   0   \n",
       "1970                                  0   \n",
       "1885                                  1   \n",
       "895                                   0   \n",
       "\n",
       "      Employment Type_Private Sector/Self Employed  Age  AnnualIncome  \\\n",
       "1857                                             0   27        900000   \n",
       "685                                              1   34       1500000   \n",
       "1970                                             1   29        500000   \n",
       "1885                                             0   35       1100000   \n",
       "895                                              1   28        600000   \n",
       "\n",
       "      FrequentFlyer  FamilyMembers  \n",
       "1857              0              4  \n",
       "685               1              4  \n",
       "1970              0              4  \n",
       "1885              0              3  \n",
       "895               0              5  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "02316c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 12)\n"
     ]
    }
   ],
   "source": [
    "# 가장 높은 점수 결정 나무, depth 5\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=[0, 2], random_state=0)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d4274a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[249   8]\n",
      " [ 59  82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       257\n",
      "           1       0.91      0.58      0.71       141\n",
      "\n",
      "    accuracy                           0.83       398\n",
      "   macro avg       0.86      0.78      0.80       398\n",
      "weighted avg       0.84      0.83      0.82       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 가공전 , 6/57\n",
    "from sklearn import tree\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# tree_model.fit(X_resampled, y_resampled)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_hat = tree_model.predict(X_test)\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "892fa658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.655608\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.626449\n",
      "[3]\tvalid_0's binary_logloss: 0.602122\n",
      "[4]\tvalid_0's binary_logloss: 0.583049\n",
      "[5]\tvalid_0's binary_logloss: 0.566604\n",
      "[6]\tvalid_0's binary_logloss: 0.553558\n",
      "[7]\tvalid_0's binary_logloss: 0.542497\n",
      "[8]\tvalid_0's binary_logloss: 0.532616\n",
      "[9]\tvalid_0's binary_logloss: 0.524257\n",
      "[10]\tvalid_0's binary_logloss: 0.517932\n",
      "[11]\tvalid_0's binary_logloss: 0.51247\n",
      "[12]\tvalid_0's binary_logloss: 0.508256\n",
      "[13]\tvalid_0's binary_logloss: 0.502065\n",
      "[14]\tvalid_0's binary_logloss: 0.497786\n",
      "[15]\tvalid_0's binary_logloss: 0.495944\n",
      "[16]\tvalid_0's binary_logloss: 0.493143\n",
      "[17]\tvalid_0's binary_logloss: 0.492166\n",
      "[18]\tvalid_0's binary_logloss: 0.490142\n",
      "[19]\tvalid_0's binary_logloss: 0.490124\n",
      "[20]\tvalid_0's binary_logloss: 0.488984\n",
      "[21]\tvalid_0's binary_logloss: 0.48892\n",
      "[22]\tvalid_0's binary_logloss: 0.48871\n",
      "[23]\tvalid_0's binary_logloss: 0.488385\n",
      "[24]\tvalid_0's binary_logloss: 0.48652\n",
      "[25]\tvalid_0's binary_logloss: 0.4865\n",
      "[26]\tvalid_0's binary_logloss: 0.487178\n",
      "[27]\tvalid_0's binary_logloss: 0.487489\n",
      "[28]\tvalid_0's binary_logloss: 0.487279\n",
      "[29]\tvalid_0's binary_logloss: 0.487164\n",
      "[30]\tvalid_0's binary_logloss: 0.487226\n",
      "[31]\tvalid_0's binary_logloss: 0.488458\n",
      "[32]\tvalid_0's binary_logloss: 0.487964\n",
      "[33]\tvalid_0's binary_logloss: 0.487734\n",
      "[34]\tvalid_0's binary_logloss: 0.488118\n",
      "[35]\tvalid_0's binary_logloss: 0.488912\n",
      "[36]\tvalid_0's binary_logloss: 0.488873\n",
      "[37]\tvalid_0's binary_logloss: 0.48827\n",
      "[38]\tvalid_0's binary_logloss: 0.488934\n",
      "[39]\tvalid_0's binary_logloss: 0.487761\n",
      "[40]\tvalid_0's binary_logloss: 0.487161\n",
      "[41]\tvalid_0's binary_logloss: 0.489253\n",
      "[42]\tvalid_0's binary_logloss: 0.490052\n",
      "[43]\tvalid_0's binary_logloss: 0.491383\n",
      "[44]\tvalid_0's binary_logloss: 0.491203\n",
      "[45]\tvalid_0's binary_logloss: 0.491702\n",
      "[46]\tvalid_0's binary_logloss: 0.491305\n",
      "[47]\tvalid_0's binary_logloss: 0.490837\n",
      "[48]\tvalid_0's binary_logloss: 0.49142\n",
      "[49]\tvalid_0's binary_logloss: 0.491738\n",
      "[50]\tvalid_0's binary_logloss: 0.492648\n",
      "[51]\tvalid_0's binary_logloss: 0.494621\n",
      "[52]\tvalid_0's binary_logloss: 0.495675\n",
      "[53]\tvalid_0's binary_logloss: 0.495922\n",
      "[54]\tvalid_0's binary_logloss: 0.496794\n",
      "[55]\tvalid_0's binary_logloss: 0.496915\n",
      "[56]\tvalid_0's binary_logloss: 0.498876\n",
      "[57]\tvalid_0's binary_logloss: 0.500021\n",
      "[58]\tvalid_0's binary_logloss: 0.50004\n",
      "[59]\tvalid_0's binary_logloss: 0.501067\n",
      "[60]\tvalid_0's binary_logloss: 0.503521\n",
      "[61]\tvalid_0's binary_logloss: 0.503703\n",
      "[62]\tvalid_0's binary_logloss: 0.503625\n",
      "[63]\tvalid_0's binary_logloss: 0.503569\n",
      "[64]\tvalid_0's binary_logloss: 0.504118\n",
      "[65]\tvalid_0's binary_logloss: 0.503383\n",
      "[66]\tvalid_0's binary_logloss: 0.503695\n",
      "[67]\tvalid_0's binary_logloss: 0.50448\n",
      "[68]\tvalid_0's binary_logloss: 0.503624\n",
      "[69]\tvalid_0's binary_logloss: 0.50455\n",
      "[70]\tvalid_0's binary_logloss: 0.504848\n",
      "[71]\tvalid_0's binary_logloss: 0.505876\n",
      "[72]\tvalid_0's binary_logloss: 0.507634\n",
      "[73]\tvalid_0's binary_logloss: 0.507404\n",
      "[74]\tvalid_0's binary_logloss: 0.508883\n",
      "[75]\tvalid_0's binary_logloss: 0.508836\n",
      "[76]\tvalid_0's binary_logloss: 0.509837\n",
      "[77]\tvalid_0's binary_logloss: 0.510497\n",
      "[78]\tvalid_0's binary_logloss: 0.51273\n",
      "[79]\tvalid_0's binary_logloss: 0.512687\n",
      "[80]\tvalid_0's binary_logloss: 0.513935\n",
      "[81]\tvalid_0's binary_logloss: 0.515063\n",
      "[82]\tvalid_0's binary_logloss: 0.515932\n",
      "[83]\tvalid_0's binary_logloss: 0.516268\n",
      "[84]\tvalid_0's binary_logloss: 0.515826\n",
      "[85]\tvalid_0's binary_logloss: 0.516183\n",
      "[86]\tvalid_0's binary_logloss: 0.51641\n",
      "[87]\tvalid_0's binary_logloss: 0.517211\n",
      "[88]\tvalid_0's binary_logloss: 0.51814\n",
      "[89]\tvalid_0's binary_logloss: 0.518098\n",
      "[90]\tvalid_0's binary_logloss: 0.518463\n",
      "[91]\tvalid_0's binary_logloss: 0.518803\n",
      "[92]\tvalid_0's binary_logloss: 0.519783\n",
      "[93]\tvalid_0's binary_logloss: 0.520031\n",
      "[94]\tvalid_0's binary_logloss: 0.520673\n",
      "[95]\tvalid_0's binary_logloss: 0.521073\n",
      "[96]\tvalid_0's binary_logloss: 0.521903\n",
      "[97]\tvalid_0's binary_logloss: 0.522375\n",
      "[98]\tvalid_0's binary_logloss: 0.522032\n",
      "[99]\tvalid_0's binary_logloss: 0.522105\n",
      "[100]\tvalid_0's binary_logloss: 0.522424\n",
      "[101]\tvalid_0's binary_logloss: 0.523471\n",
      "[102]\tvalid_0's binary_logloss: 0.523454\n",
      "[103]\tvalid_0's binary_logloss: 0.523027\n",
      "[104]\tvalid_0's binary_logloss: 0.522891\n",
      "[105]\tvalid_0's binary_logloss: 0.523396\n",
      "[106]\tvalid_0's binary_logloss: 0.524279\n",
      "[107]\tvalid_0's binary_logloss: 0.524193\n",
      "[108]\tvalid_0's binary_logloss: 0.525212\n",
      "[109]\tvalid_0's binary_logloss: 0.524927\n",
      "[110]\tvalid_0's binary_logloss: 0.525627\n",
      "[111]\tvalid_0's binary_logloss: 0.525932\n",
      "[112]\tvalid_0's binary_logloss: 0.5268\n",
      "[113]\tvalid_0's binary_logloss: 0.527159\n",
      "[114]\tvalid_0's binary_logloss: 0.52769\n",
      "[115]\tvalid_0's binary_logloss: 0.527804\n",
      "[116]\tvalid_0's binary_logloss: 0.527982\n",
      "[117]\tvalid_0's binary_logloss: 0.528484\n",
      "[118]\tvalid_0's binary_logloss: 0.528669\n",
      "[119]\tvalid_0's binary_logloss: 0.52925\n",
      "[120]\tvalid_0's binary_logloss: 0.529744\n",
      "[121]\tvalid_0's binary_logloss: 0.529693\n",
      "[122]\tvalid_0's binary_logloss: 0.53035\n",
      "[123]\tvalid_0's binary_logloss: 0.531315\n",
      "[124]\tvalid_0's binary_logloss: 0.532013\n",
      "[125]\tvalid_0's binary_logloss: 0.532337\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's binary_logloss: 0.4865\n",
      "[[231  26]\n",
      " [ 57  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       257\n",
      "           1       0.76      0.60      0.67       141\n",
      "\n",
      "    accuracy                           0.79       398\n",
      "   macro avg       0.78      0.75      0.76       398\n",
      "weighted avg       0.79      0.79      0.78       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_resampled, y_resampled, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
    "                 eval_set=evals, verbose=True)\n",
    "y_hat = lgbm_wrapper.predict(X_test)\n",
    "lgbm_wrapper_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(lgbm_wrapper_matrix)\n",
    "lgbm_wrapper_report = metrics.classification_report(y_test, y_hat)\n",
    "print(lgbm_wrapper_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b05d2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217  40]\n",
      " [ 50  91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83       257\n",
      "           1       0.69      0.65      0.67       141\n",
      "\n",
      "    accuracy                           0.77       398\n",
      "   macro avg       0.75      0.74      0.75       398\n",
      "weighted avg       0.77      0.77      0.77       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#랜덤 포레스트는 오버샘플링이 좋음\n",
    "# 오버 언더 조합도 낫베드( 데이터 개수가 늘어날 수록 좋음)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_resampled , y_resampled)\n",
    "# rf_clf.fit(X_train , y_train)\n",
    "y_hat = rf_clf.predict(X_test)\n",
    "rf_clf_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(rf_clf_matrix)\n",
    "rf_clf_report = metrics.classification_report(y_test, y_hat)\n",
    "print(rf_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb9771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7d7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
